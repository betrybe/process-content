## O que vamos aprender?

> "Qu√£o eficiente √© esse algoritmo?"

Essa pergunta j√° deve ter passado pela sua cabe√ßa em v√°rios momentos. Quando fazemos um site, por exemplo, n√£o queremos que ele seja lento: queremos um site que carregue r√°pido e responda r√°pido aos nossos comandos. Queremos uma API que n√£o demore no tempo de resposta. E √© super irritante quando abrimos um programa que deixa todo o nosso computador lento em fun√ß√£o da quantidade de **recursos** que consome.

Pois bem! Hoje vamos aprender uma **m√©trica universal** para calcular o qu√£o eficiente o seu algoritmo √©! Funciona para qualquer linguagem e paradigma de programa√ß√£o e servir√° de base para suas avalia√ß√µes de efici√™ncia daqui em diante.

---

### Voc√™ ser√° capaz de

- Analisar corretamente a ordem de complexidade de um algoritmo.

---

## Por que isso √© importante?

Para qualquer **fun√ß√£o com um valor de entrada pequeno**, n√£o damos import√¢ncia √† efici√™ncia de um algoritmo. Vai ser r√°pido e pronto. Agora, e quando sua fun√ß√£o tem que lidar com mil valores ao mesmo tempo? E cinco mil? E vinte mil? Quem sabe milh√µes de valores? A√≠ a efici√™ncia do que voc√™ est√° fazendo come√ßa a virar um problema. E n√≥s precisamos ser capazes de lidar com cen√°rios assim!

Acha esses valores exagerados? Pois exemplos n√£o faltam! O famoso [Discord](https://discord.com/) {: .external-link target="_blank" rel="noreferrer noopener" }, por exemplo, j√° encarou a demanda de ordenar alfab√©ticamente uma lista de amigos com at√© **250.000** pessoas. O tempo m√°ximo que o algoritmo tinha pra rodar? Menos de um segundo e meio. E a√≠? Vai encarar?! (Se sua curiosidade despertou, busque o artigo nos recursos adicionais desse conte√∫do depois que terminar seus estudos!)

As famosas Big Techs, por exemplo (Google, Amazon, Facebook, etc) fazem processos seletivos onde a capacidade de fazer esse tipo de an√°lise √© obrigat√≥ria. Em suma: quando sua escala fica grande, esse conhecimento se torna essencial. E com esse conhecimento voc√™ vai perceber que existem certos tipos de problemas que s√£o irresolv√≠veis mesmo que voc√™ junte toda a capacidade computacional do planeta e trabalhe nele em pot√™ncia m√°xima pelos pr√≥ximos dez mil anos. üôÇ

---

## Conte√∫dos

###### Tempo sugerido para realiza√ß√£o: 120 minutos

Observe o algoritmo abaixo:

```language-python
def sum_array(numbers):
    sum = 0
    for number in numbers:
            sum += number

    return sum
```

Quanto tempo ele vai demorar para executar? üòÅ

"Ora, imposs√≠vel dizer!", diz a pessoa incr√©dula. Depende da m√°quina, do que est√° rodando nela, dos recursos, de tudo! N√£o d√° pra dizer.

Ok. Trave todas as configura√ß√µes. √â uma m√°quina padronizada, sem mais nada rodando, tudo certo. Quanto tempo ele vai demorar para executar? Um segundo? Dez segundos?

... Tem mais um "depende" aqui, n√£o tem? O tempo de execu√ß√£o depende do tamanho do array passado por par√¢metro! **Quanto maior o dado passado por par√¢metro, mais o algoritmo demorar√° para executar**.

Hmmm. Legal! Vamos usar isso ent√£o! Eu n√£o sei quanto tempo o algoritmo vai demorar para executar: dependem de in√∫meros fatores al√©m do meu controle. Mas uma coisa eu tenho certeza: **o tempo de execu√ß√£o dele √© proporcional ao tamanho do meu dado entrado!** Por exemplo:

```language-python
# def sum_array(numbers):
  # ...

# Suponha que, para o array abaixo, o tempo de execu√ß√£o seja `n`
sum_array(array_com_dez_mil_numeros)

# Nesse caso, aqui o tempo de execu√ß√£o vai ser `10 * n`, ou `10n`, j√° que o array √© dez vezes maior que o anterior!
sum_array(array_com_cem_mil_numeros)

# J√° esse √© dez mil vezes maior que o primeiro, ent√£o esse aqui executa em `100n`
sum_array(array_com_um_milh√£o_numeros)
```

Pois bem!! A todos e a todas eu tenho o orgulho de apresentar a `Ordem de Complexidade`! Mas o que raios √© isso?! √â **o quanto que o tempo de execu√ß√£o do algoritmo varia na medida em que a entrada cresce!** Observe:

```language-python
# def sum_array(numbers):
  # ...

sum_array(array_com_dez_mil_numeros)
# O tempo de execu√ß√£o deste algoritmo foi 0.0004s

sum_array(array_com_cem_mil_numeros)
# Para uma execu√ß√£o com dez vezes mais n√∫meros, o tempo aumentou em dez vezes: 0.004s

sum_array(array_com_um_milh√£o_numeros)
# Multiplicando o tamanho da entrada por dez novamente, temos um tempo dez vezes maior: 0.05s
```

Fa√ßa o teste na sua m√°quina (voc√™ j√° tem os conhecimentos para descobrir como fazer um script que mede esses tempos üöÄ). Os valores podem variar, mas **as propor√ß√µes n√£o!** Um aumento no tamanho da entrada aumenta o tempo de execu√ß√£o na mesma propor√ß√£o. Se fiz√©ssemos um gr√°fico disso, ele seria assim:

<%= figure(%{src: "/computer-science/algorithms/complexity/images/complexidade-linear.png", class: "text-center rounded mx-auto d-block", width: "550px", height: "auto", caption: "Na medida em que o tamanho da entrada cresce, o tempo de execu√ß√£o cresce na mesma propor√ß√£o"}) %>

A Ordem de Complexidade nada mais √© do que a representa√ß√£o dessa propor√ß√£o! Dado que o algoritmo √© **linearmente proporcional** ao tempo de execu√ß√£o (ou seja, se a entrada aumenta em 10 vezes o tempo de execu√ß√£o tamb√©m aumenta em 10 vezes), dizemos que este √© um algoritmo **linear!**

A fun√ß√£o matem√°tica que representa uma rela√ß√£o linear √© `f(n) = n`. Na nota√ß√£o de Ordem de Complexidade, dizemos que esse algoritmo √© `O(n)`! Guardem essa nota√ß√£o, vamos us√°-la bastante!

> üí° A Ordem de Complexidade pode ser chamada, tamb√©m, de Complexidade Assint√≥tica.

### Complexidade de tempo e de espa√ßo

Vamos a um outro exemplo:

```language-python
def squared_array(numbers):
    array_of_squares = []
    for number in numbers:
            array_of_squares.append(number * number)

    return array_of_squares
```

Para o algoritmo acima, aumentar a entrada em dez vezes aumenta em dez vezes o tempo de execu√ß√£o! A sua ordem de complexidade, portanto, √© `O(n)`. Na maior parte das vezes em que falarmos de Ordem de Complexidade, estamos falando disso: do tempo que o algoritmo vai demorar para executar, ou **complexidade de tempo**. H√° tamb√©m uma outra complexidade: a **complexidade de espa√ßo**, se referindo ao espa√ßo em mem√≥ria que o algoritmo ocupa.

A id√©ia √© a mesma: na medida em que a entrada aumenta, quanto o espa√ßo em mem√≥ria usado pelo algoritmo aumenta? No exemplo acima, o algoritmo povoa e retorna um array de tamanho `n`, sendo `n` o tamanho do array entrado, e o retorna. Assim sendo, sua **complexidade de espa√ßo** √© `O(n)`!

> üí°  Se falamos em Ordem de Complexidade sem especificar se √© de tempo ou de mem√≥ria, assuma que √© de tempo!

Mas e o outro exemplo, o do algoritmo `sum_array()`?! Nesse caso, ele s√≥ precisa do espa√ßo, em mem√≥ria, de um n√∫mero para executar. Para **qualquer tamanho de entrada ele ocupa a mesma quantidade de espa√ßo para executar.** Assim sendo, sua complexidade de espa√ßo √© **constante**. Uma complexidade, seja de mem√≥ria ou de tempo, ser constante, significa que o tamanho da entrada n√£o influi no tempo de execu√ß√£o/mem√≥ria ocupada de um algoritmo. A nota√ß√£o para esta complexidade √© `O(1)`

> üí° Quando calculamos a complexidade de espa√ßo n√£o levamos em considera√ß√£o o espa√ßo ocupado pela entrada! O tamanho da entrada n√£o √© algo que podemos, com nosso algoritmo, influenciar, ent√£o ele n√£o entra em nossos c√°lculos.

Para fixar um pouco, vamos fazer um exerc√≠cio:

**Exerc√≠cio 1:** Qual a Ordem de Complexidade (complexidade de tempo) do algoritmo abaixo? E a complexidade de espa√ßo?

```language-python
def multiply_array(numbers):
    result = 0
    for number in numbers:
            result *= number

    return result
```

### Complexidade quadr√°tica

Observe o algoritmo abaixo:

```language-python
# Os arrays tem sempre o mesmo tamanho
def multiply_arrays(array1, array2):
    result = []
    for number1 in array1:
        for number2 in array2:
            result.append(number1 + number2)

    return result
```

Seus tempos de execu√ß√£o para um par de arrays de 2000 e 4000 elementos s√£o:

```language-python
# def multiply_array(numbers):
  # ...

sum_array(array_com_dois_mil_numeros)
# O tempo de execu√ß√£o deste algoritmo foi 0.45s

sum_array(array_com_quatro_mil_numeros)
# J√° esse teve tempo de execu√ß√£o de 1.8s, quatro vezes maior.
```

Porque, dessa vez, quando dobramos o tamanho da entrada (de 2000 para 4000) n√≥s quadruplicamos o tempo de execu√ß√£o? Ora, vejamos! Temos dois arrays do mesmo tamanho, que vamos chamar de `n`. Repare que temos dois loops aninhados um dentro do outro. Isso significa que, para cada n√∫mero de `array1`, todo o `array2` ser√° percorrido! Rode o exemplo abaixo para conferir:

```language-python
def multiply_arrays(array1, array2):
    result = []
    number_of_iterations = 0

    for number1 in array1:
        print(f'Array 1: {number1}')
        for number2 in array2:
            print(f'Array 2: {number2}')
            result.append(number1 + number2)
            number_of_iterations += 1

    print(f'{number_of_iterations} itera√ß√µes!')
    return result

array1 = [1,2,3,4,5]
array2 = [11,12,13,14,15]

multiply_arrays(array1, array2)
```

Repare como, para dois arrays de tamanho 5, temos **25 itera√ß√µes!** Varie os n√∫meros e veja como, sempre o n√∫mero de itera√ß√µes √© `n` vezes `n`, ou seja, `n¬≤`! Por isso, l√° em cima, multiplicar por dois o tamanho da entrada, de 2000 para 4000, multiplicou por quatro o tempo de execu√ß√£o: para um algoritmo `O(n¬≤)`, aumentar a entrada em `n` vezes, aumenta o tempo de execu√ß√£o em `n¬≤` vezes!

Para fixar um pouco, vamos fazer uns exerc√≠cios:

**Exerc√≠cio 2:** Para desembara√ßar a sopa de letrinhas que a se√ß√£o anterior criou, me√ßa o tempo de execu√ß√£o do algoritmo acima e, mudando o tamanho das entradas, veja como, se voc√™ aumenta a entrada em `n` vezes, o tempo de execu√ß√£o aumenta em `n¬≤` vezes!

**Exerc√≠cio 3:** Fa√ßa um algoritmo qualquer com tr√™s loops aninhados um dentro do outro. Entenda como ele ter√° uma complexidade de `O(n¬≥)`!

> Se tiver dificuldades, nos procure no Slack!

### Comparando complexidades

Beleza! Vamos resumir o que vimos at√© aqui:

- A **Ordem de Complexidade** diz o quanto o tempo de execu√ß√£o (ou espa√ßo de mem√≥ria ocupado) de um algoritmo cresce, na medida em que aumentamos o tamanho da sua entrada!

- Uma `O(1)` executa no mesmo tempo independente do tamanho da entrada. Como exemplo, lembre-se do **acesso a um elemento do array**, estudado na aula de ontem. Esse acesso √© `O(1)`, pois leva o mesmo tempo, independente do tamanho do array;

- Uma `O(n)` significa que o algoritmo √© **linear**: se aumentamos a entrada em **2 vezes**, aumentamos o tempo de execu√ß√£o em **2 vezes**;

- Uma `O(n¬≤)` significa que o algoritmo √© **quadr√°tico**: se aumentamos a entrada em **2 vezes**, aumentamos o tempo de execu√ß√£o em **4 (2¬≤) vezes**;

- Uma `O(n¬≥)` significa que o algoritmo √© **c√∫bico**: se aumentamos a entrada em **2 vezes**, aumentamos o tempo de execu√ß√£o em **8 (2¬≥) vezes**.

<%= figure(%{src: "/computer-science/algorithms/complexity/images/nazareconfusamatematica.gif", class: "text-center rounded mx-auto d-block", width: "450px", height: "auto", caption: "Vamos com calma pros n√∫meros n√£o confundirem!"}) %>

Falamos aqui de algoritmos `O(n)`, `O(n¬≤)` e at√© de `O(n¬≥)`, mas vamos mostrar o que eles significam de outra forma. Observe, antes, o gr√°fico abaixo, e veja sobre como o **tempo de execu√ß√£o** de um algoritmo c√∫bico cresce muito mais para uma entrada **muito menor** que a do algoritmo linear:

<%= figure(%{src: "/computer-science/algorithms/complexity/images/comparacao-ordens-de-complexidade.png", class: "text-center rounded mx-auto d-block", width: "550px", height: "auto", caption: "Observe no gr√°fico a rela√ß√£o entre as ordens de complexidade linear, quadr√°tica e c√∫bica"}) %>

Para se ter uma no√ß√£o, pense assim: para um algoritmo linear, com `n = 1000` temos mil opera√ß√µes. Quando o algoritmo √© `O(n¬≤)` um `n = 1000` gera **um milh√£o de opera√ß√µes**. Essa mesma quantidade (um milh√£o) para `O(n¬≥)`, se atinge com `n = 100`. Est√° come√ßando a entender como alguns algoritmos podem, rapidinho, ficar invi√°veis de se executar?

A seguir, vamos explorar outros tipos de complexidades de algoritmos!

>üí° Lembre-se! Se voc√™ se embananar com essa quantidade de n√∫meros, rode exemplos na sua m√°quina contando o n√∫mero de itera√ß√µes! √â uma excelente forma de visualizar a complexidade acontecendo. E n√£o deixe de falar com a gente no Slack se algum exemplo estiver te confundindo!

### Complexidade logar√≠tmica

**Calma!** Apesar do termo potencialmente assustador, a complexidade **logar√≠tmica** n√£o exige c√°lculos matem√°ticos complicados para ser entendida. Dado pela nota√ß√£o `O(log n)`, um algoritmo **logar√≠tmico** geralmente reduz pela metade o tamanho do input a cada itera√ß√£o.

> O tempo de execu√ß√£o de um algoritmo √© dito logar√≠tmico porque _log‚ÇÇn_ (l√™-se: "log de n na base 2") √© igual ao n√∫mero de vezes que _n_ deve ser dividido por 2 para obter 1.

No exemplo a seguir temos um algoritmo de busca bin√°ria. Dado um array de tamanho `n` ordenado em ordem crescente, **encontre um n√∫mero passado na entrada**. √â como procurar por um nome numa lista telef√¥nica!

<%= figure(%{src: "/computer-science/algorithms/complexity/images/lista-telefonica.png", class: "text-center rounded mx-auto d-block", width: "550px", height: "auto", caption: "Rel√≠quia de um passado remoto. "}) %>

Como voc√™ faz? Suponha que voc√™ quer procurar pelo nome `Tintim`. Voc√™ abre numa p√°gina qualquer e v√™ que est√° na letra `M`. Como `M < T` na ordem alfab√©tica, voc√™ sabe que o nome que procura est√° adiante na lista. Voc√™ pega a parte da lista que est√° √† frente de `M` e abre ela novamente a esmo. Agora voc√™ abriu no `V`. Como `V > T`, voc√™ sabe que o nome `Tintim` est√° para tr√°s. Repita at√© encontrar o nome que procura.

Observe o gif abaixo para entender melhor. Ele compara o algoritmo de **busca bin√°ria**, logar√≠tmico, com a **busca sequencial**, que √© linear.

<%= figure(%{src: "/computer-science/algorithms/complexity/images/binary-and-linear-search-animations.gif", class: "text-center rounded mx-auto d-block", width: "700px", height: "auto"}) %>

Se quiser rodar seus pr√≥prios testes, o algoritmo de busca bin√°ria √© o abaixo:

```language-python
data = [1, 2, 9, 8, 3, 4, 7, 6, 5, 10]

def binary_search_iterative(array, element):
    mid = 0
    start = 0
    end = len(array)
    step = 0

    while (start <= end):
        print("Subarray in step {}: {}".format(step, str(array[start: end + 1])))
        step = step + 1
        mid = (start + end) // 2

        if element == array[mid]:
            return mid

        if element < array[mid]:
            end = mid - 1
        else:
            start = mid + 1

    return - 1


print(binary_search_iterative(data, 2))
```

Observe como, a cada itera√ß√£o, o algoritmo de busca bin√°ria corta o problema pela metade: primeiro ele corta a lista em dois e pega o elemento do meio. Depois ele vai para o lado onde o elemento que procura est√° e corta este lado novamente pela metade. Quando cortamos a entrada pela metade, a cada itera√ß√£o, temos um padr√£o que segue a fun√ß√£o matem√°tica de logaritmo na base dois! Assim, nosso algoritmo √© `O(log n)`.

Dessa forma, sem precisarmos nos aprofundar na matem√°tica, conseguimos calcular a ordem de complexidade de um algoritmo deste tipo! Quando a entrada √© cortada pela metade a cada itera√ß√£o temos um comportamento logar√≠tmico!

<%= figure(%{src: "/computer-science/algorithms/complexity/images/logaritmo-vs-linear.png", class: "text-center rounded mx-auto d-block", width: "550px", height: "auto", caption: "Um algoritmo logar√≠tmico √© muito superior a um linear!"}) %>

Para fixar um pouco, vamos fazer um exerc√≠cio:

**Exerc√≠cio 4:** Imagine que voc√™ recebe dois arrays de tamanho igual, `array1` e `array2`. Para cada elemento do `array1`, realize uma busca bin√°ria no `array2`. Mostre que a ordem de complexidade do algoritmo resultante √© `O(n * log n)`, ou `O(n log n)`.

### Complexidade exponencial e fatorial

Essas complexidades caracterizam algoritmos que, para aumentos pequenos no tamanho da entrada, aumentam enormemente o seu tempo de execu√ß√£o. Para a rela√ß√£o do tempo de execu√ß√£o/espa√ßo ocupado em cada caso √© a seguinte:

- **Exponencial:** `2‚Åø`;

- **Fatorial:** `n!`.

No caso exponencial, se `n` possui vinte elementos, o algoritmo faz um milh√£o de opera√ß√µes. Para o caso fatorial, os mesmos vinte elementos rendem 24 **quatrilh√µes** de opera√ß√µes (O n√∫mero exato √©: 2432902008176640000 opera√ß√µes üò®).

Da√≠ vem a pergunta: **porque algu√©m iria escrever um algoritmo de complexidade fatorial?!** A resposta √© simples: quando n√£o h√° outro algoritmo conhecido que resolve o problema. Quer conhecer um cl√°ssico? Eis o problema do **caixeiro viajante**! Seu enunciado √©: _"Dada uma lista de cidade e a dist√¢ncia entre cada par de cidades, qual √© a rota mais curta poss√≠vel que visita todas as cidades exatamente uma vez e volta para a cidade de origem?"_

A √∫nica solu√ß√£o exata conhecida para este problema √© a `for√ßa bruta`. Ou seja: voc√™ testa todas as possibilidades. Imagine que voc√™ tem tr√™s cidades: Belo Horizonte, S√£o Paulo e Florian√≥polis. Temos as seguintes rotas poss√≠veis, basta list√°-las e escolher a mais curta:

```language-bash
- Belo Horizonte > S√£o Paulo > Florian√≥polis

- Belo Horizonte > Florian√≥polis > S√£o Paulo

- Florian√≥polis > Belo Horizonte > S√£o Paulo

- Florian√≥polis > S√£o Paulo > Belo Horizonte

- S√£o Paulo > Belo Horizonte > Florian√≥polis

- S√£o Paulo > Florian√≥polis > Belo Horizonte
```

O n√∫mero de rotas para 3 cidades √© `3! == 3 * 2 * 1 = 6`. Atualmente o Brasil tem `5570` munic√≠pios. Quantos milhares de anos um computador precisaria para rodar esse algoritmo nesse caso? üòÑ

Algoritmos que n√£o tem solu√ß√£o conhecida em tempo polinomial, ou seja, **que s√£o fatoriais ou exponenciais**, resolv√≠veis somente com for√ßa bruta, pertencem a uma categoria de problemas na computa√ß√£o chamada problemas **NP Completos**. Se quiser conhecer mais sobre essa categoria de problemas, explore nossos recursos adicionais!

### Analisando algoritmos com v√°rias estruturas de repeti√ß√£o

E quando temos um algoritmo como o abaixo?

```language-python
def calculations(n):
    number1 = 0
    for n1 in range(n):
        number1 += n1

    number2 = 0
    for n1 in range(n):
       for n2 in range(n):
            number2 += n1 + n2

    number3 = 0
    for n1 in range(n):
       for n2 in range(n):
           for n3 in range(n):
               number3 += n1 + n2 + n3

    return number1, number2, number3

n1, n2, n3 = calculations(100)
print(f'{n1}, {n2}, {n3}')
```

Esse algoritmo tem tr√™s estruturas de repeti√ß√£o evidentes: uma linear, uma quadr√°tica e uma c√∫bica. Qual √© a ordem de complexidade dele?!

A rigor, ela seria `O(n + n¬≤ + n¬≥)`. Se os loops est√£o aninhados voc√™ os multiplica, e se est√£o paralelos voc√™ os soma. Podemos pensar em alguns outros exemplos:

- Um algoritmo de busca bin√°ria que roda tr√™s vezes = `O(3 * log n)`;

- Um algoritmo que roda uma busca bin√°ria num array de tamanho `n` para cada elemento de um array de tamanho `m` = `O(m * log n)`.

No entanto, geralmente simplificam-se essas nota√ß√µes. Estamos vendo, ao longo dos nossos estudos, que ordens de complexidade diferentes, para entradas grandes, tem valores absurdamente diferentes. Imagine escrever `O(n! + log(n))`. Ora, para uma entrada de tamanho `8` esse n√∫mero seria `O(40320 + 3)`. Observe como o componente fatorial da equa√ß√£o, `n! = 40320`, domina completamente a ordem de complexidade. Nesse cen√°rio dizemos que a complexidade menor √© **desprez√≠vel**, ent√£o a omitimos.

Ou seja: para valores grandes, dizer a maior ordem de complexidade do conjunto j√° basta para uma boa an√°lise. Ent√£o, ao analisar v√°rias estruturas de repeti√ß√£o em paralelo, responda somente com o valor da estrutura que tiver maior ordem de complexidade na hora de fazer a sua an√°lise!

<%= figure(%{src: "/computer-science/algorithms/complexity/images/todas-as-complexidades.png", class: "text-center rounded mx-auto d-block", width: "550px", height: "auto", caption: "Quando a entrada vai ficando grande, veja como cresce a diferen√ßa de desempenho das diferentes ordens de complexidade"}) %>

### Melhor caso, pior caso e caso m√©dio

H√° um √∫ltimo conceito importante para aprendermos aqui antes de passarmos para a aula ao vivo e os exerc√≠cios! Voc√™s ver√£o nos pr√≥ximos dias e blocos do curso muitas vezes os termos "melhor caso", "pior caso" e "caso m√©dio". Eles significam o seguinte: "A depender da minha entrada, o meu algoritmo pode executar em `O(1)` ou `O(n)`". Por exemplo, pense na busca sequencial:

```language-python
def linear_search(numbers, n):
    for index, number in enumerate(numbers):
        if(number == n): return index

    return -1

print(linear_search([1, 2, 3, 4, 5], 4))
```

Dizemos que, para entradas muito grandes, esse algoritmo √© `O(n)`. O que acontece, por√©m, caso tenhamos sorte e o n√∫mero que procuramos seja o primeiro do array? Nesse caso, mesmo para uma entrada infinita, nossa complexidade ser√° `O(1)`. Esse √© o **melhor caso** desse algoritmo. De forma an√°loga, o **pior caso** √© o n√∫mero ser o √∫ltimo elemento do array, ou seja `O(n)`.

E o caso m√©dio? Bem, seria algo como `O(n * 1/2)`, por exemplo (ou seja, o n√∫mero que procuramos est√° no meio da lista). Mas, para entradas muito grandes, aprendemos a desprezar os n√∫meros menos relevantes da soma, ent√£o podemos simplificar e dizer que o caso m√©dio √© `O(n)` tamb√©m.

Diferentes algoritmos tem diferentes cen√°rios de melhor caso, pior caso e caso m√©dio! Voc√™ ver√° v√°rios exemplo ao longo dos pr√≥ximos blocos!

### Em suma

Hoje estudamos **ordens de complexidade**, uma forma de se analisar um algoritmo de qualquer linguagem e feito em qualquer paradigma. Vemos que existem algoritmos dos seguintes tipos:

- **Constantes:** `O(1)`;

- **Logar√≠tmicos:** `O(log n)`;

- **Linear:** `O(n)`;

- **Quadr√°ticos:** `O(n¬≤)`;

- **C√∫bicos:** `O(n¬≥)`;

- **Exponencial:** `O(2‚Åø)`;

- **Fatorial:** `O(n!)`.

Vimos tamb√©m que, a depender do algoritmo, essas an√°lises podem ser combinadas, como por exemplo num algoritmo `O(n log n)`. Por fim, vimos que problemas que n√£o tem solu√ß√£o conhecida em tempo polinomial, sendo apenas exponenciais ou fatoriais, em algoritmos de for√ßa bruta, s√£o chamados **NP Completo**.

Vimos que, em algoritmos com v√°rias estruturas de repeti√ß√£o diferentes, devemos sempre considerar a maior ordem de complexidade poss√≠vel e desprezar as demais na nossa nota√ß√£o. E vimos que algoritmos podem ter diferentes ordens de complexidade para seu melhor caso, pior caso e caso m√©dio.

---

## Vamos fazer juntos!

###### Tempo sugerido para realiza√ß√£o: 80 minutos

Com toda essa matem√°tica em mente, vamos praticar nossa capacidade de an√°lise na aula ao vivo!

Bora pro Slack, onde o link estar√° dispon√≠vel. üòâ

---

## Exerc√≠cios

###### Tempo sugerido para realiza√ß√£o: 100 minutos

<%= versioning_your_code(@conn) %>

---

### Agora a pr√°tica

Vamos colocar tudo o que vimos at√© agora em pr√°tica.

**Exerc√≠cio 1** Dado um array de n√∫meros de tamanho `n`, escreva um algoritmo que retorna `true` se h√° no array um n√∫mero duplicado e `false` caso contr√°rio. Analise a solu√ß√£o abaixo e diga qual √© a ordem de complexidade desse algoritmo para o melhor caso, pior caso e caso m√©dio.

```language-python
def contains_duplicate(numbers):
    numbers.sort()
    previous_number = 'not a number';
    for number in numbers:
        if(previous_number == number): return True
        previous_number = number

    return False
```

**Exerc√≠cio 2** Suponha que se est√° escrevendo uma fun√ß√£o para um jogo de batalha naval. Dado um array bidimensional com `n` linhas e `m` colunas, e um par de coordenadas `x` para linhas e `y` para colunas, o algoritmo verifica se h√° um navio na coordenada alvo. Por exemplo:

```language-bash
entrada = [ 0 0 0 0 1
            0 0 0 0 1
            1 1 1 1 1
            0 0 0 1 0 ]

resultado para (0, 4) = True
resultado para (1, 1) = False
```

Qual seria a ordem de complexidade da solu√ß√£o para este problema? E a complexidade de espa√ßo?

**Exerc√≠cio 3** O c√≥digo abaixo est√° em **JavaScript**. Calcule sua ordem de complexidade para um array de tamanho `n`.

```language-javascript
const numbers = [0,1,2,3,4,5,6,7,8,9]
numbers.map(n => n*n)
```

**Exerc√≠cio 4** O c√≥digo abaixo est√° em **JavaScript**. Calcule sua ordem de complexidade para um array de tamanho `n`.

```language-javascript
const numbers = [0,1,2,3,4,5,6,7,8,9]
numbers.map(n => n*n)
       .filter(n => n%2 === 0)
       .reduce((acc, n) => acc + n)
```

**Exerc√≠cio 5** Utilize o m√≥dulo `random` da linguagem Python para gerar um array com 100 n√∫meros. Cada um desses n√∫meros deve ser a m√©dia de dez n√∫meros gerados aleat√≥riamente. Qual √© a ordem de complexidade de tempo e de espa√ßo deste programa?

**Exerc√≠cio 6** Dado um array de doces candies e um valor inteiro extra_candies, onde o candies[i] representa o n√∫mero de doces que a en√©sima crian√ßa possui. Para cada crian√ßa, verifique se h√° uma maneira de distribuir doces extras entre as crian√ßas de forma que ela possa ter o maior n√∫mero de doces entre elas. Observe que v√°rias crian√ßas podem ter o maior n√∫mero de doces. Analise o c√≥digo abaixo para o melhor, pior caso e caso m√©dio. Fa√ßa a analise de complexidade de espa√ßo tamb√©m.

```language-python
def kids_with_candies(candies, extra_candies):
    # parece que a solu√ß√£o percorre o array somente uma vez,
    # por√©m isto √© feito duas vezes, uma no `max` e outra para
    # preencher a resposta
    max_candies = max(candies)
    return [candy + extra_candies >= max_candies for candy in candies]


# sa√≠da: [True, True, True, False, True]
print(kids_with_candies([2, 3, 5, 1, 3], 3))
```

---

### Recursos Adicionais

- [O que √© um problema NP completo? - Stack Overflow](https://pt.stackoverflow.com/a/34131) {: .external-link target="_blank" rel="noreferrer noopener" }

- [Competitive Programmer‚Äôs Handbook ](https://cses.fi/book/book.pdf) {: .external-link target="_blank" rel="noreferrer noopener" }

- [Using Rust to Scale Elixir for 11 Million Concurrent Users](https://blog.discord.com/using-rust-to-scale-elixir-for-11-million-concurrent-users-c6f19fc029d3) {: .external-link target="_blank" rel="noreferrer noopener" }

- [Understanding time complexity with Python ](https://towardsdatascience.com/understanding-time-complexity-with-python-examples-2bda6e8158a7) {: .external-link target="_blank" rel="noreferrer noopener" }

---

## Pr√≥ximo

<%= next_button(@conn) %>
